{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup \n",
    "\n",
    "speech_recognition\n",
    "tensorflow\n",
    "nltk\n",
    "\n",
    "The probablistic model developed from\n",
    "https://github.com/NathanDuran/Probabilistic-RNN-DA-Classifier\n",
    "will be used to make prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.1\n",
      "Loaded data from file data/metadata.pkl.\n",
      "Loaded data from file embeddings/probabilistic_freq_2.pkl.\n"
     ]
    }
   ],
   "source": [
    "#Speech to text \n",
    "import speech_recognition as sr\n",
    "print(sr.__version__)\n",
    "r = sr.Recognizer()\n",
    "#define microphone object for microphone input\n",
    "mic = sr.Microphone()\n",
    "\n",
    "#Dialog act classification\n",
    "import os\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_dir = 'models/'\n",
    "model_name = 'Probabilistic Model'\n",
    "\n",
    "num_epoch = 10\n",
    "hidden_layer = 128\n",
    "\n",
    "model_name = model_name + \" -\" + \\\n",
    "             \" Epochs=\" + str(num_epoch) + \\\n",
    "             \" Hidden Layers=\" + str(hidden_layer)\n",
    "\n",
    "p_model = load_model(model_dir + model_name + '.hdf5')\n",
    "\n",
    "#to preprocess data the same way, the utilities.py file from the prior project needs to be imported\n",
    "from utilities import *\n",
    "\n",
    "resource_dir = 'data/'\n",
    "embeddings_dir = \"embeddings/\"\n",
    "embedding_filename = 'word2vec_swda'\n",
    "model_dir = 'models/'\n",
    "model_name = \"Embeddings Model\"\n",
    "\n",
    "# Load metadata\n",
    "metadata = load_data(resource_dir + \"metadata.pkl\")\n",
    "word_frequency = 2\n",
    "frequency_data = load_data(embeddings_dir + 'probabilistic_freq_' + str(word_frequency) + '.pkl')\n",
    "\n",
    "\n",
    "#to tokenize the input\n",
    "import nltk\n",
    "\n",
    "# compile the model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "learning_rate = 0.001\n",
    "optimizer = RMSprop(lr=learning_rate, decay=0.001)\n",
    "\n",
    "p_model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run as many times from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening\n"
     ]
    }
   ],
   "source": [
    "print(\"Listening\")\n",
    "\n",
    "#microphone records\n",
    "#after a period of time with no input, it will stop listening automatically\n",
    "with mic as source:\n",
    "    r.adjust_for_ambient_noise(source)\n",
    "    audio = r.listen(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fire in the hole fire in the hole'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#application of speech recognition using google speech api\n",
    "r.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fire in the hole fire in the hole\n"
     ]
    }
   ],
   "source": [
    "input_text = r.recognize_google(audio)\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fire in the hole fire in the hole\n",
      "{'utterances': [['fire', 'in', 'the', 'hole', 'fire', 'in', 'the', 'hole']], 'labels': ['%']}\n"
     ]
    }
   ],
   "source": [
    "print(input_text)\n",
    "\n",
    "#Convert to same format for input\n",
    "utterances = []\n",
    "labels = []\n",
    "utterances.append(nltk.word_tokenize(input_text))\n",
    "#set a default label for processing\n",
    "labels.append('%') \n",
    "\n",
    "# Save input to same data structure\n",
    "data = dict(\n",
    "    utterances=utterances,\n",
    "    labels=labels)\n",
    "\n",
    "#save_data(resource_dir + \"input\" + \"_data.pkl\", data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating probabilistic embeddings in the same format as training\n",
    "ins_x, ins_y = generate_probabilistic_embeddings(data, frequency_data, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "result=p_model.predict(ins_x,batch_size=100, verbose=1)\n",
    "\n",
    "# generating predictions.\n",
    "index_to_label = metadata[\"index_to_label\"]\n",
    "prediction=index_to_label[np.argmax(result)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: fire in the hole fire in the hole\n",
      "Prediction: qh\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \" + input_text)\n",
    "print(\"Prediction: \" + prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
