{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## University of North Texas\n",
    "### CSCE 5280 AI for wearables\n",
    "\n",
    "### Dialog act aware conversation response generator\n",
    "\n",
    "#### Project 1\n",
    "\n",
    "#### Shou-Jen Wang\n",
    "#### Eric Hedrick\n",
    "#### Ashwin Thota\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup \n",
    "\n",
    "speech_recognition\n",
    "tensorflow\n",
    "nltk\n",
    "\n",
    "The probablistic model developed from\n",
    "https://github.com/NathanDuran/Probabilistic-RNN-DA-Classifier\n",
    "will be used to make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.1\n",
      "Loaded data from file data/metadata.pkl.\n",
      "Loaded data from file embeddings/probabilistic_freq_2.pkl.\n"
     ]
    }
   ],
   "source": [
    "#Speech to text \n",
    "import speech_recognition as sr\n",
    "print(sr.__version__)\n",
    "\n",
    "#Dialog act classification\n",
    "import os\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_dir = 'models/'\n",
    "model_name = 'Probabilistic Model'\n",
    "\n",
    "num_epoch = 10\n",
    "hidden_layer = 128\n",
    "\n",
    "model_name = model_name + \" -\" + \\\n",
    "             \" Epochs=\" + str(num_epoch) + \\\n",
    "             \" Hidden Layers=\" + str(hidden_layer)\n",
    "\n",
    "p_model = load_model(model_dir + model_name + '.hdf5')\n",
    "\n",
    "#to preprocess data the same way, the utilities.py file from the prior project needs to be imported\n",
    "from utilities import *\n",
    "\n",
    "resource_dir = 'data/'\n",
    "embeddings_dir = \"embeddings/\"\n",
    "embedding_filename = 'word2vec_swda'\n",
    "model_dir = 'models/'\n",
    "model_name = \"Embeddings Model\"\n",
    "\n",
    "# Load metadata\n",
    "metadata = load_data(resource_dir + \"metadata.pkl\")\n",
    "word_frequency = 2\n",
    "frequency_data = load_data(embeddings_dir + 'probabilistic_freq_' + str(word_frequency) + '.pkl')\n",
    "\n",
    "\n",
    "#to tokenize the input\n",
    "import nltk\n",
    "\n",
    "# compile the model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "learning_rate = 0.001\n",
    "optimizer = RMSprop(lr=learning_rate, decay=0.001)\n",
    "\n",
    "p_model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# response - did not have time to develop fully\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('dialog_act_table.csv', skip_blank_lines = True)\n",
    "da_tbl = df.dropna()\n",
    "\n",
    "#read the response file to get example responses\n",
    "df = pd.read_csv('dialog_act_response.csv', skip_blank_lines = True)\n",
    "#drop descriptive columns\n",
    "drop_column = [0, 2, 4]\n",
    "df_responses = df.drop(df.columns[drop_column], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run as many times from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening\n"
     ]
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "#define microphone object for microphone input\n",
    "mic = sr.Microphone()\n",
    "\n",
    "#microphone records\n",
    "#after a period of time with no input, it will stop listening automatically\n",
    "try:\n",
    "    print(\"Listening\")\n",
    "    with mic as source:\n",
    "        r.adjust_for_ambient_noise(source)\n",
    "        audio = r.listen(source)\n",
    "except KeyboardInterrupt: \n",
    "    pass\n",
    "  \n",
    "print(\"Processing audio.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do you have a favorite color\n"
     ]
    }
   ],
   "source": [
    "#application of speech recognition using google speech api\n",
    "input_text = r.recognize_google(audio)\n",
    "\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do you have a favorite color\n",
      "{'utterances': [['do', 'you', 'have', 'a', 'favorite', 'color']], 'labels': ['%']}\n"
     ]
    }
   ],
   "source": [
    "#Convert to same format for input\n",
    "utterances = []\n",
    "labels = []\n",
    "utterances.append(nltk.word_tokenize(input_text))\n",
    "#set a default label for processing\n",
    "labels.append('%') \n",
    "\n",
    "# Save input to same data structure\n",
    "data = dict(\n",
    "    utterances=utterances,\n",
    "    labels=labels)\n",
    "\n",
    "#save_data(resource_dir + \"input\" + \"_data.pkl\", data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating probabilistic embeddings in the same format as training\n",
    "ins_x, ins_y = generate_probabilistic_embeddings(data, frequency_data, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step\n",
      "qy\n"
     ]
    }
   ],
   "source": [
    "result=p_model.predict(ins_x,batch_size=100, verbose=1)\n",
    "\n",
    "# generating predictions.\n",
    "index_to_label = metadata[\"index_to_label\"]\n",
    "prediction=index_to_label[np.argmax(result)]\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine if the dialog act should generate a response\n",
    "\n",
    "row = da_tbl[da_tbl.columns[1]]==prediction\n",
    "response = da_tbl.loc[row]['Response']\n",
    "#print(response.dtype)\n",
    "reply = response.iloc[0]\n",
    "\n",
    "if reply.lower() == 'yes':\n",
    "    response = df_responses.loc[df_responses[df_responses.columns[0]]==prediction]['Example response']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: do you have a favorite color\n",
      "Prediction dialog act: qy\n",
      "Response 1 :Yes!\n",
      "Response 2 :I cannot reach it\n",
      "Response 3 :I might be able to pick it up\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \" + input_text)\n",
    "print(\"Prediction dialog act: \" + prediction)\n",
    "if reply.lower() == 'no':\n",
    "    print(\"Generate reply:\" + reply)\n",
    "else:\n",
    "    count = 1\n",
    "    for label, reply in response.items():\n",
    "        if reply.lower() == 'x':\n",
    "            print(\"More context is required to generate a response.\")\n",
    "        else:\n",
    "            print(\"Response \" + str(count) +\" :\"+ reply)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
